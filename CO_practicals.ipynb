{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7a3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Hypothesis: ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Find-S Algorithm\n",
    "def findS(examples):\n",
    "    hypothesis = examples[0].copy()\n",
    "\n",
    "    for example in examples:\n",
    "        if example[-1] == \"Yes\":\n",
    "            for i in range(len(hypothesis)-1):\n",
    "                if example[i] != hypothesis[i]:\n",
    "                    hypothesis[i] = \"?\"\n",
    "    return hypothesis\n",
    "\n",
    "data = [\n",
    "    [\"Sunny\", \"Warm\", \"Normal\", \"Strong\", \"Warm\", \"Same\", \"Yes\"],\n",
    "    [\"Sunny\", \"Warm\", \"High\", \"Strong\", \"Warm\", \"Same\", \"Yes\"],\n",
    "    [\"Rainy\", \"Cold\", \"High\", \"Strong\", \"Warm\", \"Change\", \"No\"]\n",
    "]\n",
    "\n",
    "print(\"Final Hypothesis:\", findS(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb468280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific: (['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same'], [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']])\n"
     ]
    }
   ],
   "source": [
    "def candidate_elimination(data):\n",
    "    S = data[0][:-1].copy()  \n",
    "    G = [[\"?\" for _ in S]]\n",
    "\n",
    "    for example in data:\n",
    "        attrs, output = example[:-1], example[-1]\n",
    "\n",
    "        if output == \"Yes\":\n",
    "            for i in range(len(S)):\n",
    "                if S[i] != attrs[i]:\n",
    "                    S[i] = \"?\"\n",
    "            G = [g for g in G if all(g[i] == \"?\" or g[i] == attrs[i] for i in range(len(g)))]\n",
    "\n",
    "        else:  \n",
    "            new_G = []\n",
    "            for i in range(len(S)):\n",
    "                if S[i] != attrs[i]:\n",
    "                    g = [\"?\" for _ in S]\n",
    "                    g[i] = S[i]\n",
    "                    new_G.append(g)\n",
    "            G = new_G\n",
    "    return S, G\n",
    "data = [\n",
    "    [\"Sunny\", \"Warm\", \"Normal\", \"Strong\", \"Warm\", \"Same\", \"Yes\"],\n",
    "    [\"Sunny\", \"Warm\", \"High\", \"Strong\", \"Warm\", \"Same\", \"Yes\"],\n",
    "    [\"Rainy\", \"Cold\", \"High\", \"Strong\", \"Warm\", \"Change\", \"No\"]\n",
    "]\n",
    "\n",
    "print(\"Specific:\", candidate_elimination(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2075aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook 0.2516291673878229\n",
      "Wind 0.2516291673878229\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "import pandas as pd\n",
    "\n",
    "def entropy(col):\n",
    "    values = col.value_counts(normalize=True)\n",
    "    return -sum(p * log2(p) for p in values)\n",
    "\n",
    "def info_gain(df, attr, target):\n",
    "    total_entropy = entropy(df[target])\n",
    "    vals = df[attr].unique()\n",
    "    weighted = 0\n",
    "\n",
    "    for v in vals:\n",
    "        subset = df[df[attr] == v]\n",
    "        weighted += (len(subset)/len(df)) * entropy(subset[target])\n",
    "    return total_entropy - weighted\n",
    "\n",
    "# Example dataset\n",
    "df = pd.DataFrame({\n",
    "    \"Outlook\": [\"Sunny\", \"Rainy\", \"Sunny\"],\n",
    "    \"Wind\": [\"Strong\", \"Weak\", \"Strong\"],\n",
    "    \"Play\": [\"No\", \"Yes\", \"Yes\"]\n",
    "})\n",
    "\n",
    "for col in df.columns[:-1]:\n",
    "    print(col, info_gain(df, col, \"Play\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbebe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same'], 6), (['?', 'Warm', '?', 'Strong', 'Warm', 'Same'], 6), (['Sunny', '?', '?', 'Strong', 'Warm', 'Same'], 6)]\n"
     ]
    }
   ],
   "source": [
    "def heuristic(hyp, example):\n",
    "    return sum(hyp[i] == example[i] or hyp[i] == \"?\" for i in range(len(hyp)))\n",
    "\n",
    "hypotheses = [\n",
    "    [\"Sunny\",\"Warm\",\"?\",\"Strong\",\"Warm\",\"Same\"],\n",
    "    [\"?\",\"Warm\",\"?\",\"Strong\",\"Warm\",\"Same\"],\n",
    "    [\"Sunny\",\"?\",\"?\",\"Strong\",\"Warm\",\"Same\"]\n",
    "]\n",
    "\n",
    "example = [\"Sunny\",\"Warm\",\"Normal\",\"Strong\",\"Warm\",\"Same\"]\n",
    "\n",
    "scores = [(h, heuristic(h, example)) for h in hypotheses]\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389bc37",
   "metadata": {},
   "source": [
    "#CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee02be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.2 0.1]\n",
      "Bias: -0.20000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "weights = np.zeros(2)\n",
    "bias = 0\n",
    "lr = 0.1\n",
    "\n",
    "def activation(z):\n",
    "    return 1 if z >= 0 else 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(len(X)):\n",
    "        z = np.dot(X[i], weights) + bias\n",
    "        y_pred = activation(z)\n",
    "        error = y[i] - y_pred\n",
    "        weights += lr * error * X[i]\n",
    "        bias += lr * error\n",
    "\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d1bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after training:\n",
      " [[0.25840124]\n",
      " [0.69139438]\n",
      " [0.69130801]\n",
      " [0.39872979]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "W1 = np.random.rand(2,2)\n",
    "W2 = np.random.rand(2,1)\n",
    "lr = 0.1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    h = sigmoid(np.dot(X, W1))\n",
    "    out = sigmoid(np.dot(h, W2))\n",
    "\n",
    "    error = y - out\n",
    "    d_out = error * sigmoid_derivative(out)\n",
    "    d_h = d_out.dot(W2.T) * sigmoid_derivative(h)\n",
    "\n",
    "    W2 += h.T.dot(d_out) * lr\n",
    "    W1 += X.T.dot(d_h) * lr\n",
    "\n",
    "print(\"Output after training:\\n\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d6e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa77add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Solution: 25\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "population_size = 6\n",
    "generations = 10\n",
    "population = [random.randint(0, 31) for _ in range(population_size)]\n",
    "\n",
    "def fitness(x):\n",
    "    return x*x\n",
    "\n",
    "for g in range(generations):\n",
    "    population = sorted(population, key=fitness, reverse=True)\n",
    "    parents = population[:2]\n",
    "    children = []\n",
    "\n",
    "    for _ in range(population_size - 2):\n",
    "        child = random.choice(parents)\n",
    "        if random.random() < 0.1:\n",
    "            child = random.randint(0, 31)\n",
    "        children.append(child)\n",
    "\n",
    "    population = parents + children\n",
    "\n",
    "print(\"Best Solution:\", population[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c185dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Mask: [1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "population = np.random.randint(0, 2, size=(6, X.shape[1]))\n",
    "\n",
    "def fitness(mask):\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0\n",
    "    X_sel = X[:, mask==1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.3)\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "scores = [fitness(ind) for ind in population]\n",
    "best = population[np.argmax(scores)]\n",
    "print(\"Best Feature Mask:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007ed21",
   "metadata": {},
   "source": [
    "#CO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615acb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probability (Yes): 0.84\n",
      "Posterior Probability (No): 0.16000000000000003\n"
     ]
    }
   ],
   "source": [
    "# Bayes Theorem based classification\n",
    "p_yes = 0.6\n",
    "p_no = 0.4\n",
    "p_x_given_yes = 0.7\n",
    "p_x_given_no = 0.2\n",
    "\n",
    "p_yes_given_x = (p_x_given_yes * p_yes) / (\n",
    "    p_x_given_yes * p_yes + p_x_given_no * p_no\n",
    ")\n",
    "p_no_given_x = 1 - p_yes_given_x\n",
    "\n",
    "print(\"Posterior Probability (Yes):\", p_yes_given_x)\n",
    "print(\"Posterior Probability (No):\", p_no_given_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a563518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Mean: 5.0\n",
      "Estimated Variance: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([4, 5, 6, 5, 4, 6, 5])\n",
    "\n",
    "mean_mle = np.mean(X)\n",
    "var_mle = np.var(X)\n",
    "\n",
    "print(\"Estimated Mean:\", mean_mle)\n",
    "print(\"Estimated Variance:\", var_mle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1e680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,1],[1,0],[0,1],[0,0]])\n",
    "y = np.array(['Yes','Yes','No','No'])\n",
    "\n",
    "classes = np.unique(y)\n",
    "priors = {}\n",
    "likelihood = {}\n",
    "\n",
    "for c in classes:\n",
    "    X_c = X[y == c]\n",
    "    priors[c] = len(X_c) / len(X)\n",
    "    likelihood[c] = np.mean(X_c, axis=0)\n",
    "\n",
    "x_test = np.array([1,1])\n",
    "posteriors = {}\n",
    "\n",
    "for c in classes:\n",
    "    posteriors[c] = priors[c] * np.prod(likelihood[c] ** x_test)\n",
    "\n",
    "print(\"Prediction:\", max(posteriors, key=posteriors.get))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead7f427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09fff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels: [0 2 1 1 1 1 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, _ = make_blobs(n_samples=200, centers=3, random_state=42)\n",
    "\n",
    "model = GaussianMixture(n_components=3)\n",
    "model.fit(X)\n",
    "\n",
    "labels = model.predict(X)\n",
    "print(\"Cluster Labels:\", labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3ce98",
   "metadata": {},
   "source": [
    "#CO4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2786299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "X_train = np.array([[1,2],[2,3],[3,3],[6,5],[7,7]])\n",
    "y_train = np.array(['A','A','A','B','B'])\n",
    "X_test = np.array([3,4])\n",
    "K = 3\n",
    "\n",
    "def euclidean(a, b):\n",
    "    return np.sqrt(np.sum((a-b)**2))\n",
    "\n",
    "distances = []\n",
    "for i in range(len(X_train)):\n",
    "    dist = euclidean(X_train[i], X_test)\n",
    "    distances.append((dist, y_train[i]))\n",
    "\n",
    "distances.sort(key=lambda x: x[0])\n",
    "neighbors = distances[:K]\n",
    "labels = [n[1] for n in neighbors]\n",
    "\n",
    "prediction = Counter(labels).most_common(1)[0][0]\n",
    "print(\"Predicted Class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafb0fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, Accuracy=0.95\n",
      "K=2, Accuracy=0.93\n",
      "K=3, Accuracy=0.95\n",
      "K=4, Accuracy=0.96\n",
      "K=5, Accuracy=0.97\n",
      "K=6, Accuracy=0.96\n",
      "K=7, Accuracy=0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "for k in range(1, 8):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(f\"K={k}, Accuracy={scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5a731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: 2.9787890051301127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "y = np.array([1.2,1.9,3.0,3.9,5.1])\n",
    "x0 = 3\n",
    "tau = 0.5\n",
    "\n",
    "weights = np.exp(-(X - x0)**2 / (2 * tau**2))\n",
    "X_bias = np.c_[np.ones(len(X)), X]\n",
    "W = np.diag(weights)\n",
    "\n",
    "theta = np.linalg.inv(X_bias.T @ W @ X_bias) @ X_bias.T @ W @ y\n",
    "prediction = theta[0] + theta[1] * x0\n",
    "\n",
    "print(\"Predicted Value:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39e99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: [0. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.array([[1,2],[1,3],[2,2],[6,5],[7,6],[8,7]])\n",
    "y = np.array([0,0,0,1,1,1])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "sigma = 1.0\n",
    "def rbf(x, c):\n",
    "    return np.exp(-np.linalg.norm(x-c)**2 / (2*sigma**2))\n",
    "\n",
    "Phi = np.array([[rbf(x, c) for c in centers] for x in X])\n",
    "weights = np.linalg.pinv(Phi) @ y\n",
    "\n",
    "pred = np.round(Phi @ weights)\n",
    "print(\"Predicted Labels:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5159180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Case: Case1\n",
      "Predicted Solution: Low\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cases = {\n",
    "    'Case1': np.array([1,1]),\n",
    "    'Case2': np.array([2,2]),\n",
    "    'Case3': np.array([5,5])\n",
    "}\n",
    "\n",
    "solutions = {\n",
    "    'Case1': 'Low',\n",
    "    'Case2': 'Medium',\n",
    "    'Case3': 'High'\n",
    "}\n",
    "\n",
    "query = np.array([2,1])\n",
    "\n",
    "def similarity(a, b):\n",
    "    return 1 / (1 + np.linalg.norm(a-b))\n",
    "\n",
    "scores = {c: similarity(v, query) for c, v in cases.items()}\n",
    "best_case = max(scores, key=scores.get)\n",
    "\n",
    "print(\"Retrieved Case:\", best_case)\n",
    "print(\"Predicted Solution:\", solutions[best_case])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9749af2b",
   "metadata": {},
   "source": [
    "#CO5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f577ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Rules:\n",
      "IF ['Overcast', 'Hot', 'High', 'Weak'] THEN Yes\n",
      "IF ['Rain', 'Mild', 'High', 'Weak'] THEN Yes\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ['Sunny','Hot','High','Weak','No'],\n",
    "    ['Sunny','Hot','High','Strong','No'],\n",
    "    ['Overcast','Hot','High','Weak','Yes'],\n",
    "    ['Rain','Mild','High','Weak','Yes']\n",
    "]\n",
    "\n",
    "rules = []\n",
    "for row in data:\n",
    "    if row[-1] == 'Yes':\n",
    "        rules.append(row[:-1])\n",
    "\n",
    "print(\"Learned Rules:\")\n",
    "for r in rules:\n",
    "    print(\"IF\", r, \"THEN Yes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233ff3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Rules:\n",
      " |--- feature_3 <= 0.80\n",
      "|   |--- class: 0\n",
      "|--- feature_3 >  0.80\n",
      "|   |--- feature_3 <= 1.75\n",
      "|   |   |--- feature_2 <= 4.95\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- feature_2 >  4.95\n",
      "|   |   |   |--- class: 2\n",
      "|   |--- feature_3 >  1.75\n",
      "|   |   |--- feature_2 <= 4.85\n",
      "|   |   |   |--- class: 2\n",
      "|   |   |--- feature_2 >  4.85\n",
      "|   |   |   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "rules = export_text(model)\n",
    "print(\"Extracted Rules:\\n\", rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf489c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Rule: IF temperature < 100 AND fuel > 50 THEN SAFE\n"
     ]
    }
   ],
   "source": [
    "def is_safe(temp, fuel):\n",
    "    return temp < 100 and fuel > 50\n",
    "\n",
    "example = {'temp': 80, 'fuel': 60}\n",
    "\n",
    "if is_safe(example['temp'], example['fuel']):\n",
    "    rule = \"IF temperature < 100 AND fuel > 50 THEN SAFE\"\n",
    "    print(\"Learned Rule:\", rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e5e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Table:\n",
      " [[0.7232872  0.        ]\n",
      " [0.80842464 0.        ]\n",
      " [0.89971048 0.        ]\n",
      " [0.99997344 0.        ]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "states = 5\n",
    "actions = 2\n",
    "Q = np.zeros((states, actions))\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "for episode in range(100):\n",
    "    state = 0\n",
    "    while state < states - 1:\n",
    "        action = np.argmax(Q[state])\n",
    "        next_state = state + 1\n",
    "        reward = 1 if next_state == states - 1 else 0\n",
    "        Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
    "        state = next_state\n",
    "\n",
    "print(\"Q-Table:\\n\", Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3696b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Q-Values:\n",
      " [[0.62121641 0.70169294 0.62136463 0.701608  ]\n",
      " [0.70149103 0.79080788 0.62124379 0.79068831]\n",
      " [0.79063169 0.88984734 0.7008746  0.79044685]\n",
      " [0.62115661 0.79080199 0.70160127 0.79087551]\n",
      " [0.70097544 0.88993966 0.70133157 0.88978313]\n",
      " [0.78740317 0.99993144 0.79058746 0.88876391]\n",
      " [0.70127913 0.79063546 0.79022344 0.88990399]\n",
      " [0.78663974 0.88930847 0.78882417 0.99998971]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Q = np.zeros((9,4))\n",
    "\n",
    "def next_state(state, action):\n",
    "    row, col = divmod(state, 3)\n",
    "    if action == 0 and row > 0: row -= 1\n",
    "    if action == 1 and row < 2: row += 1\n",
    "    if action == 2 and col > 0: col -= 1\n",
    "    if action == 3 and col < 2: col += 1\n",
    "    return row*3 + col\n",
    "\n",
    "for _ in range(200):\n",
    "    s = 0\n",
    "    while s != 8:\n",
    "        a = np.random.randint(4)\n",
    "        ns = next_state(s, a)\n",
    "        reward = 1 if ns == 8 else -0.01\n",
    "        Q[s,a] += 0.1 * (reward + 0.9 * np.max(Q[ns]) - Q[s,a])\n",
    "        s = ns\n",
    "\n",
    "print(\"Optimized Q-Values:\\n\", Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a0a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
